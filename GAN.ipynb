{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                     int64\n",
      "dur                  float64\n",
      "proto                 object\n",
      "service               object\n",
      "state                 object\n",
      "spkts                  int64\n",
      "dpkts                  int64\n",
      "sbytes                 int64\n",
      "dbytes                 int64\n",
      "rate                 float64\n",
      "sttl                   int64\n",
      "dttl                   int64\n",
      "sload                float64\n",
      "dload                float64\n",
      "sloss                  int64\n",
      "dloss                  int64\n",
      "sinpkt               float64\n",
      "dinpkt               float64\n",
      "sjit                 float64\n",
      "djit                 float64\n",
      "swin                   int64\n",
      "stcpb                  int64\n",
      "dtcpb                  int64\n",
      "dwin                   int64\n",
      "tcprtt               float64\n",
      "synack               float64\n",
      "ackdat               float64\n",
      "smean                  int64\n",
      "dmean                  int64\n",
      "trans_depth            int64\n",
      "response_body_len      int64\n",
      "ct_srv_src             int64\n",
      "ct_state_ttl           int64\n",
      "ct_dst_ltm             int64\n",
      "ct_src_dport_ltm       int64\n",
      "ct_dst_sport_ltm       int64\n",
      "ct_dst_src_ltm         int64\n",
      "is_ftp_login           int64\n",
      "ct_ftp_cmd             int64\n",
      "ct_flw_http_mthd       int64\n",
      "ct_src_ltm             int64\n",
      "ct_srv_dst             int64\n",
      "is_sm_ips_ports        int64\n",
      "attack_cat            object\n",
      "label                  int64\n",
      "dtype: object\n",
      "         id       dur  proto  service  state     spkts     dpkts    sbytes  \\\n",
      "0 -1.732041 -0.191029    113        0      2 -0.104456 -0.135769 -0.049134   \n",
      "1 -1.732021 -0.109485    113        0      2 -0.046014  0.172599 -0.046410   \n",
      "2 -1.732001  0.040699    113        0      2 -0.089845 -0.026933 -0.048527   \n",
      "3 -1.731982  0.049729    113        3      2 -0.060624 -0.063212 -0.047016   \n",
      "4 -1.731962 -0.140417    113        0      2 -0.075235 -0.117630 -0.047554   \n",
      "\n",
      "     dbytes      rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
      "0 -0.102726 -0.576371  ...         -0.554373       -0.705529     -0.118590   \n",
      "1  0.188544 -0.576345  ...         -0.554373       -0.614256     -0.118590   \n",
      "2 -0.012133 -0.576734  ...         -0.554373       -0.522983     -0.118590   \n",
      "3 -0.098563 -0.576737  ...         -0.554373       -0.522983      7.814915   \n",
      "4 -0.102057 -0.576617  ...         -0.554373        2.854115     -0.118590   \n",
      "\n",
      "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
      "0   -0.118590         -0.189768   -0.715714   -0.753074        -0.126508   \n",
      "1   -0.118590         -0.189768   -0.715714   -0.288257        -0.126508   \n",
      "2   -0.118590         -0.189768   -0.595543   -0.288257        -0.126508   \n",
      "3    7.814915         -0.189768   -0.595543   -0.753074        -0.126508   \n",
      "4   -0.118590         -0.189768   -0.595543    2.779535        -0.126508   \n",
      "\n",
      "   attack_cat     label  \n",
      "0           6 -1.459825  \n",
      "1           6 -1.459825  \n",
      "2           6 -1.459825  \n",
      "3           6 -1.459825  \n",
      "4           6 -1.459825  \n",
      "\n",
      "[5 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = 'UNSW_NB15_training-set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Hiển thị kiểu dữ liệu của các cột\n",
    "print(df.dtypes)\n",
    "\n",
    "# Lựa chọn các cột số và cột không phải là số\n",
    "numeric_columns = df.select_dtypes(include=['number']).columns\n",
    "categorical_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Chuyển đổi các cột không phải là số sang mã số\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Chuẩn hóa dữ liệu cho các cột số\n",
    "scaler = StandardScaler()\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# Kiểm tra lại dữ liệu đã chuẩn hóa\n",
    "print(df.head())\n",
    "\n",
    "# Dữ liệu đã được chuẩn hóa và chuyển đổi sẵn sàng để sử dụng cho mô hình GAN\n",
    "data = df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss D: 0.06830091774463654, Loss G: 5.1047821044921875\n",
      "Epoch [200/1000], Loss D: 0.4101049304008484, Loss G: 31.186555862426758\n",
      "Epoch [300/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [400/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [500/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [600/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [700/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [800/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [900/1000], Loss D: 0.0, Loss G: 100.0\n",
      "Epoch [1000/1000], Loss D: 0.0, Loss G: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Định nghĩa các siêu tham số\n",
    "input_dim = 100  # Kích thước của vector ngẫu nhiên đầu vào cho Generator\n",
    "output_dim = data.shape[1]  # Kích thước của dữ liệu đầu ra\n",
    "batch_size = 64\n",
    "num_epochs = 1000\n",
    "lr = 0.0002\n",
    "\n",
    "# Tạo các mô hình Generator và Discriminator\n",
    "generator = Generator(input_dim, output_dim)\n",
    "discriminator = Discriminator(output_dim)\n",
    "\n",
    "# Định nghĩa các hàm mất mát và bộ tối ưu hóa\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# Huấn luyện mô hình GAN\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, data.shape[0], batch_size):\n",
    "        # Tạo batch dữ liệu thật\n",
    "        real_data = torch.tensor(data[i:i+batch_size], dtype=torch.float32)\n",
    "        real_labels = torch.ones(real_data.size(0), 1)\n",
    "        \n",
    "        # Tạo batch dữ liệu giả\n",
    "        noise = torch.randn(real_data.size(0), input_dim)\n",
    "        fake_data = generator(noise)\n",
    "        fake_labels = torch.zeros(fake_data.size(0), 1)\n",
    "        \n",
    "        # Huấn luyện Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "        outputs_real = discriminator(real_data)\n",
    "        loss_real = criterion(outputs_real, real_labels)\n",
    "        outputs_fake = discriminator(fake_data.detach())\n",
    "        loss_fake = criterion(outputs_fake, fake_labels)\n",
    "        loss_d = loss_real + loss_fake\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Huấn luyện Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        outputs_fake = discriminator(fake_data)\n",
    "        loss_g = criterion(outputs_fake, real_labels)\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinh khoảng 15 triệu mẫu dữ liệu giả\n",
    "num_samples = 15000000  # Số lượng mẫu dữ liệu giả cần sinh\n",
    "batch_size = 10000  # Kích thước mỗi batch để sinh dữ liệu giả\n",
    "\n",
    "fake_data_list = []\n",
    "for _ in range(num_samples // batch_size):\n",
    "    noise = torch.randn(batch_size, input_dim)\n",
    "    fake_data_batch = generator(noise).detach().numpy()\n",
    "    fake_data_list.append(fake_data_batch)\n",
    "\n",
    "# Kết hợp tất cả các batch thành một mảng numpy lớn\n",
    "fake_data = np.vstack(fake_data_list)\n",
    "\n",
    "# Kiểm tra số lượng cột của dữ liệu giả trước khi chuyển đổi\n",
    "assert fake_data.shape[1] == scaler.mean_.shape[0], \"Số lượng cột của dữ liệu giả không khớp với dữ liệu gốc.\"\n",
    "\n",
    "# Chuyển đổi dữ liệu giả về dạng ban đầu\n",
    "fake_data = scaler.inverse_transform(fake_data)\n",
    "\n",
    "# Tạo DataFrame từ dữ liệu giả\n",
    "fake_df = pd.DataFrame(fake_data, columns=df.columns)\n",
    "\n",
    "# Lưu toàn bộ dữ liệu giả vào một tệp CSV\n",
    "fake_df.to_csv('generated_data_15m_samples.csv', index=False)\n",
    "print('Generated data saved to generated_data_15m_samples.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
